{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "V100",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mpnsk/ivy_seminar/blob/main/my_ivy_mnist.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z3UjSxxzSYm4",
        "outputId": "32cb78c5-683d-477b-ba24-676aefa82d0a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting ivy\n",
            "  Downloading ivy-0.0.0.0.0-py3-none-any.whl (10.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.0/10.0 MB\u001b[0m \u001b[31m18.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from ivy) (1.23.5)\n",
            "Collecting einops (from ivy)\n",
            "  Downloading einops-0.6.1-py3-none-any.whl (42 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.2/42.2 kB\u001b[0m \u001b[31m4.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from ivy) (5.9.5)\n",
            "Requirement already satisfied: termcolor in /usr/local/lib/python3.10/dist-packages (from ivy) (2.3.0)\n",
            "Collecting colorama (from ivy)\n",
            "  Downloading colorama-0.4.6-py2.py3-none-any.whl (25 kB)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from ivy) (23.1)\n",
            "Collecting nvidia-ml-py (from ivy)\n",
            "  Downloading nvidia_ml_py-12.535.77-py3-none-any.whl (36 kB)\n",
            "Collecting diskcache (from ivy)\n",
            "  Downloading diskcache-5.6.1-py3-none-any.whl (45 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m45.6/45.6 kB\u001b[0m \u001b[31m4.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: google-auth in /usr/local/lib/python3.10/dist-packages (from ivy) (2.17.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from ivy) (2.31.0)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth->ivy) (5.3.1)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth->ivy) (0.3.0)\n",
            "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.10/dist-packages (from google-auth->ivy) (1.16.0)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth->ivy) (4.9)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->ivy) (3.2.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->ivy) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->ivy) (2.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->ivy) (2023.7.22)\n",
            "Requirement already satisfied: pyasn1<0.6.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth->ivy) (0.5.0)\n",
            "Installing collected packages: nvidia-ml-py, einops, diskcache, colorama, ivy\n",
            "Successfully installed colorama-0.4.6 diskcache-5.6.1 einops-0.6.1 ivy-0.0.0.0.0 nvidia-ml-py-12.535.77\n",
            "Collecting dm-haiku\n",
            "  Downloading dm_haiku-0.0.10-py3-none-any.whl (360 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m360.3/360.3 kB\u001b[0m \u001b[31m4.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: absl-py>=0.7.1 in /usr/local/lib/python3.10/dist-packages (from dm-haiku) (1.4.0)\n",
            "Collecting jmp>=0.0.2 (from dm-haiku)\n",
            "  Downloading jmp-0.0.4-py3-none-any.whl (18 kB)\n",
            "Requirement already satisfied: numpy>=1.18.0 in /usr/local/lib/python3.10/dist-packages (from dm-haiku) (1.23.5)\n",
            "Requirement already satisfied: tabulate>=0.8.9 in /usr/local/lib/python3.10/dist-packages (from dm-haiku) (0.9.0)\n",
            "Installing collected packages: jmp, dm-haiku\n",
            "Successfully installed dm-haiku-0.0.10 jmp-0.0.4\n"
          ]
        }
      ],
      "source": [
        "!pip install ivy\n",
        "!pip install dm-haiku"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import ivy\n",
        "my_backend = \"torch\"\n",
        "# my_backend = \"tensorflow\"\n",
        "# my_backend = \"jax\"\n",
        "\n",
        "# ivy.set_default_device(\"cpu\")\n",
        "\n",
        "ivy.set_exception_trace_mode('full')\n",
        "\n",
        "doCompile = True\n",
        "\n",
        "ivy.set_backend(my_backend)\n",
        "if my_backend == \"jax\":\n",
        "  import jax\n",
        "  jax.config.update('jax_enable_x64', True)\n",
        "\n",
        "\n",
        "# as of the pytorch mnist example https://github.com/pytorch/examples/blob/main/mnist/main.py\n",
        "class Net(ivy.Module):\n",
        "    def __init__(self):\n",
        "        self.conv1 = ivy.Conv2D(1, 32, [3, 3], 1, \"VALID\")\n",
        "        self.conv2 = ivy.Conv2D(32, 64, [3, 3], 1, \"VALID\")\n",
        "        self.conv1_drop = ivy.Dropout(0.25)\n",
        "        self.conv2_drop = ivy.Dropout(0.5)\n",
        "        self.fc1 = ivy.Linear(9216, 128)\n",
        "        self.fc2 = ivy.Linear(128, 10)\n",
        "        super().__init__()\n",
        "\n",
        "    def _forward(self, x):\n",
        "        x = self.conv1(x)\n",
        "        x = ivy.relu(x)\n",
        "        x = self.conv2(x)\n",
        "        x = ivy.relu(x)\n",
        "        x = ivy.max_pool2d(x, 2, 2, 'VALID')\n",
        "        x = self.conv1_drop(x)\n",
        "        x = ivy.flatten(x, start_dim=1)\n",
        "        x = self.fc1(x)\n",
        "        x = ivy.relu(x)\n",
        "        x = self.conv2_drop(x)\n",
        "        x = self.fc2(x)\n",
        "        x = ivy.softmax(x)\n",
        "        return x\n",
        "\n",
        "\n",
        "def loss_fn(v, x, y):\n",
        "    entropy = ivy.sparse_cross_entropy(y, model(x))\n",
        "    entropy = entropy.mean()\n",
        "    return entropy\n",
        "\n",
        "\n",
        "if doCompile:\n",
        "  print(\"starting compilation\")\n",
        "  model = ivy.compile(Net(), to=my_backend, args=(ivy.random_normal(shape=(60,28,28,1)),))\n",
        "else:\n",
        "  model = Net()\n",
        "print(\"done\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MkcTfkXhxt3R",
        "outputId": "604a0a54-d9ad-4cce-a189-5bf908109bb4"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "starting compilation\n",
            "done\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print('loading mnist')\n",
        "from keras.datasets import mnist\n",
        "(train_X_np, train_y_np), (test_X, test_y) = mnist.load_data()\n",
        "del test_X # I'm not there yet, lol\n",
        "del test_y\n",
        "\n",
        "# no need to look at all 60,000 samples as of now\n",
        "limit = 6400\n",
        "train_X_np = train_X_np[:limit, :, :]\n",
        "train_y_np = train_y_np[:limit]\n",
        "\n",
        "# batch parameters\n",
        "batch_size = 64\n",
        "num_batches = limit // batch_size\n",
        "\n",
        "print('starting to batch')\n",
        "## convert to ivy\n",
        "print(f\"{type(train_X_np)=}\")\n",
        "train_X_ivy = ivy.array(train_X_np)\n",
        "print(f\"{type(train_X_ivy)=}\")\n",
        "print(f\"{type(train_X_ivy.data)=}\")\n",
        "\n",
        "train_y_ivy = ivy.array(train_y_np)\n",
        "\n",
        "# normalize from grey scale to 0.0-1.0\n",
        "train_X_ivy = train_X_ivy / 255\n",
        "\n",
        "# expand data from nhw to nhwc\n",
        "train_X_ivy = ivy.expand_dims(train_X_ivy, axis=-1)\n",
        "\n",
        "# turn big array into list of batched arrays\n",
        "train_X_batches = [train_X_ivy[i*batch_size:(i+1)*batch_size] for i in range(num_batches)]\n",
        "train_y_batches = [train_y_ivy[i*batch_size:(i+1)*batch_size] for i in range(num_batches)]\n",
        "print('done')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IkJoeZIQ63BF",
        "outputId": "efdf2a50-9ed3-4fd1-d375-de2fd3ca411a"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loading mnist\n",
            "starting to batch\n",
            "type(train_X_np)=<class 'numpy.ndarray'>\n",
            "type(train_X_ivy)=<class 'ivy.data_classes.array.array.Array'>\n",
            "type(train_X_ivy.data)=<class 'torch.Tensor'>\n",
            "done\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for idx in range(num_batches):\n",
        "    loss, grads = ivy.execute_with_gradients(lambda v: loss_fn(v, train_X_batches[idx], train_y_batches[idx]), model.v)\n",
        "    print(f'{idx=}, {loss=}')\n",
        "    # print(f\"{grads=}\")\n",
        "    if grads.all().cont_all_false():\n",
        "        print(\"ERROR!\")\n",
        "        # print(f'{grads.conv1.w=}')\n",
        "        # print(f'{grads.conv1.b=}')\n",
        "        # print(f'{grads.conv2.w=}')\n",
        "        # print(f'{grads.conv2.b=}')\n",
        "        # print(f'{grads.fc1.w=}')\n",
        "        # print(f'{grads.fc1.b=}')\n",
        "        # print(f'{grads.fc2.w=}')\n",
        "        # print(f'{grads.fc2.b=}')\n",
        "        # break\n",
        "    ivy.multiply(grads, 0.0005, out=grads)\n",
        "    ivy.subtract(model.v, grads, out=model.v)\n",
        "    # model.v = ivy.subtract(model.v, ivy.multiply(grads, 0.0005))\n",
        "\n"
      ],
      "metadata": {
        "id": "bm8LKSTXShKI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "random_index = 3\n",
        "\n",
        "x = train_X_ivy[random_index]\n",
        "# expand hwc to nhwc\n",
        "x = ivy.expand_dims(x, axis=0)\n",
        "prediction = model(x)\n",
        "print(f'{prediction=}')\n",
        "print(f'{ivy.argmax(prediction)=}')\n",
        "print(f'{train_y_ivy[random_index]=}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bL23x8HB3zvh",
        "outputId": "23ebe5f3-9843-4725-b02c-1df33c948d42"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "prediction=tensor([[0.0157, 0.1683, 0.0212, 0.1423, 0.2341, 0.0110, 0.0387, 0.1549, 0.0814,\n",
            "         0.1326]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "ivy.argmax(prediction)=ivy.array(4, dev=gpu:0)\n",
            "train_y_ivy[random_index]=ivy.array(1, dev=gpu:0)\n"
          ]
        }
      ]
    }
  ]
}