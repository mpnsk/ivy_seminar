{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "A100",
      "authorship_tag": "ABX9TyMhMdV5LE/k9nneYmJVDSMo",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mpnsk/ivy_seminar/blob/main/my_ivy_mnist.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Z3UjSxxzSYm4"
      },
      "outputs": [],
      "source": [
        "!pip install ivy\n",
        "!pip install dm-haiku"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import ivy"
      ],
      "metadata": {
        "id": "pt--jXAayGXq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "my_backend = \"torch\"\n",
        "# my_backend = \"tensorflow\"\n",
        "# my_backend = \"jax\"\n",
        "\n",
        "# ivy.set_default_device(\"cpu\")\n",
        "\n",
        "\n",
        "doCompile = True\n",
        "\n",
        "if my_backend == \"jax\":\n",
        "  import jax\n",
        "  jax.config.update('jax_enable_x64', True)\n",
        "\n",
        "ivy.set_backend(my_backend)\n",
        "\n",
        "# as of the pytorch mnist example https://github.com/pytorch/examples/blob/main/mnist/main.py\n",
        "class Net(ivy.Module):\n",
        "    def __init__(self):\n",
        "        self.conv1 = ivy.Conv2D(1, 32, [3, 3], 1, \"VALID\")\n",
        "        self.conv2 = ivy.Conv2D(32, 64, [3, 3], 1, \"VALID\")\n",
        "        self.conv1_drop = ivy.Dropout(0.25)\n",
        "        self.conv2_drop = ivy.Dropout(0.5)\n",
        "        self.fc1 = ivy.Linear(9216, 128)\n",
        "        self.fc2 = ivy.Linear(128, 10)\n",
        "        super().__init__()\n",
        "\n",
        "    def _forward(self, x):\n",
        "        x = self.conv1(x)\n",
        "        ivy.relu(x, out=x)\n",
        "        x = self.conv2(x)\n",
        "        ivy.relu(x, out=x)\n",
        "        x = ivy.max_pool2d(x, 2, 2, 'VALID')\n",
        "        x = self.conv1_drop(x)\n",
        "        x = ivy.flatten(x, start_dim=1)\n",
        "        x = self.fc1(x)\n",
        "        ivy.relu(x, out=x)\n",
        "        x = self.conv2_drop(x)\n",
        "        x = self.fc2(x)\n",
        "        x = ivy.softmax(x)\n",
        "        return x\n",
        "\n",
        "\n",
        "def loss_fn(v, x, y):\n",
        "    entropy = ivy.sparse_cross_entropy(y, model(x))\n",
        "    entropy = entropy.mean()\n",
        "    return entropy\n",
        "\n",
        "\n",
        "if doCompile:\n",
        "  print(\"starting compilation\")\n",
        "  model = ivy.compile(Net(), to=my_backend, args=(ivy.random_normal(shape=(1,28,28,1)),))\n",
        "else:\n",
        "  model = Net()\n",
        "print(\"done\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MkcTfkXhxt3R",
        "outputId": "8e01e182-ceae-4276-fa22-c93b880f4d27"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "starting compilation\n",
            "done\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print('loading mnist')\n",
        "from keras.datasets import mnist\n",
        "(train_X_np, train_y_np), (test_X, test_y) = mnist.load_data()\n",
        "del test_X # I'm not there yet, lol\n",
        "del test_y\n",
        "\n",
        "# no need to look at all 60,000 samples as of now\n",
        "limit = 320\n",
        "train_X_np = train_X_np[:limit, :, :]\n",
        "train_y_np = train_y_np[:limit]\n",
        "\n",
        "# batch parameters\n",
        "batch_size = 32\n",
        "num_batches = limit // batch_size\n",
        "\n",
        "print('starting to batch')\n",
        "## convert to ivy\n",
        "train_X_ivy = ivy.array(train_X_np)\n",
        "train_y_ivy = ivy.array(train_y_np)\n",
        "\n",
        "# normalize from grey scale to 0.0-1.0\n",
        "train_X_ivy = train_X_ivy / 255\n",
        "\n",
        "# expand data from nhw to nhwc\n",
        "train_X_ivy = ivy.expand_dims(train_X_ivy, axis=-1)\n",
        "\n",
        "# turn big array into list of batched arrays\n",
        "train_X_batches = [train_X_ivy[i*batch_size:(i+1)*batch_size] for i in range(num_batches)]\n",
        "train_y_batches = [train_y_ivy[i*batch_size:(i+1)*batch_size] for i in range(num_batches)]\n",
        "print('done')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IkJoeZIQ63BF",
        "outputId": "813570af-04f9-47a4-dfe9-b949d8f1e040"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loading mnist\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
            "11490434/11490434 [==============================] - 2s 0us/step\n",
            "starting to batch\n",
            "done\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for idx in range(num_batches):\n",
        "    loss, grads = ivy.execute_with_gradients(lambda v: loss_fn(v, train_X_batches[idx], train_y_batches[idx]), model.v)\n",
        "    print(f'{idx=}, {loss=}')\n",
        "    if grads.all().cont_all_false():\n",
        "        print(\"ERROR!\")\n",
        "        print(f'{grads.conv1.w=}')\n",
        "        print(f'{grads.conv1.b=}')\n",
        "        print(f'{grads.conv2.w=}')\n",
        "        print(f'{grads.conv2.b=}')\n",
        "        print(f'{grads.fc1.w=}')\n",
        "        print(f'{grads.fc1.b=}')\n",
        "        print(f'{grads.fc2.w=}')\n",
        "        print(f'{grads.fc2.b=}')\n",
        "        break\n",
        "    model.v = model.v - grads * 0.005\n",
        "\n",
        "\n",
        "random_index = 3\n",
        "\n",
        "x = train_X_ivy[random_index]\n",
        "# expand hwc to nhwc\n",
        "x = ivy.expand_dims(x, axis=0)\n",
        "prediction = model(x)\n",
        "print(f'{prediction=}')\n",
        "print(f'{ivy.argmax(prediction)=}')\n",
        "print(f'{train_y_ivy[random_index]=}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bm8LKSTXShKI",
        "outputId": "93a0b67b-b014-488d-c693-ce0df846c66b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "idx=0, loss=ivy.array(3.5656419)\n",
            "idx=1, loss=ivy.array(4.7978497)\n",
            "idx=2, loss=ivy.array(3.5605125)\n",
            "idx=3, loss=ivy.array(3.1029253)\n",
            "idx=4, loss=ivy.array(3.1441267)\n",
            "idx=5, loss=ivy.array(2.9305246)\n",
            "idx=6, loss=ivy.array(2.9057436)\n",
            "idx=7, loss=ivy.array(1.7976189)\n",
            "idx=8, loss=ivy.array(1.1552026)\n",
            "idx=9, loss=ivy.array(1.3361251)\n",
            "prediction=tensor([[0.0169, 0.1191, 0.0124, 0.0245, 0.0169, 0.0825, 0.0679, 0.0223, 0.6305,\n",
            "         0.0070]], grad_fn=<SoftmaxBackward0>)\n",
            "ivy.argmax(prediction)=ivy.array(8)\n",
            "train_y_ivy[random_index]=ivy.array(1)\n"
          ]
        }
      ]
    }
  ]
}