{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyNN4uX3WFmhzHMbngn6ho02",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mpnsk/ivy_seminar/blob/main/my_ivy_mnist.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z3UjSxxzSYm4",
        "outputId": "01eb2bd8-a59e-4f8d-cde7-47d75c7dfe81"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting ivy\n",
            "  Downloading ivy-0.0.0.0.0-py3-none-any.whl (10.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.0/10.0 MB\u001b[0m \u001b[31m23.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from ivy) (1.23.5)\n",
            "Collecting einops (from ivy)\n",
            "  Downloading einops-0.6.1-py3-none-any.whl (42 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.2/42.2 kB\u001b[0m \u001b[31m3.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from ivy) (5.9.5)\n",
            "Requirement already satisfied: termcolor in /usr/local/lib/python3.10/dist-packages (from ivy) (2.3.0)\n",
            "Collecting colorama (from ivy)\n",
            "  Downloading colorama-0.4.6-py2.py3-none-any.whl (25 kB)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from ivy) (23.1)\n",
            "Collecting nvidia-ml-py (from ivy)\n",
            "  Downloading nvidia_ml_py-12.535.77-py3-none-any.whl (36 kB)\n",
            "Collecting diskcache (from ivy)\n",
            "  Downloading diskcache-5.6.1-py3-none-any.whl (45 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m45.6/45.6 kB\u001b[0m \u001b[31m4.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: google-auth in /usr/local/lib/python3.10/dist-packages (from ivy) (2.17.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from ivy) (2.31.0)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth->ivy) (5.3.1)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth->ivy) (0.3.0)\n",
            "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.10/dist-packages (from google-auth->ivy) (1.16.0)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth->ivy) (4.9)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->ivy) (3.2.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->ivy) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->ivy) (1.26.16)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->ivy) (2023.7.22)\n",
            "Requirement already satisfied: pyasn1<0.6.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth->ivy) (0.5.0)\n",
            "Installing collected packages: nvidia-ml-py, einops, diskcache, colorama, ivy\n",
            "Successfully installed colorama-0.4.6 diskcache-5.6.1 einops-0.6.1 ivy-0.0.0.0.0 nvidia-ml-py-12.535.77\n",
            "Collecting dm-haiku\n",
            "  Downloading dm_haiku-0.0.10-py3-none-any.whl (360 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m360.3/360.3 kB\u001b[0m \u001b[31m7.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: absl-py>=0.7.1 in /usr/local/lib/python3.10/dist-packages (from dm-haiku) (1.4.0)\n",
            "Collecting jmp>=0.0.2 (from dm-haiku)\n",
            "  Downloading jmp-0.0.4-py3-none-any.whl (18 kB)\n",
            "Requirement already satisfied: numpy>=1.18.0 in /usr/local/lib/python3.10/dist-packages (from dm-haiku) (1.23.5)\n",
            "Requirement already satisfied: tabulate>=0.8.9 in /usr/local/lib/python3.10/dist-packages (from dm-haiku) (0.9.0)\n",
            "Installing collected packages: jmp, dm-haiku\n",
            "Successfully installed dm-haiku-0.0.10 jmp-0.0.4\n"
          ]
        }
      ],
      "source": [
        "!pip install ivy\n",
        "!pip install dm-haiku"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import ivy\n",
        "my_backend = \"torch\"\n",
        "# my_backend = \"tensorflow\"\n",
        "# my_backend = \"jax\"\n",
        "\n",
        "## stuff I tried\n",
        "doCompile = True\n",
        "ivy.set_default_device(\"cpu\")\n",
        "# if my_backend == \"jax\":\n",
        "  # import jax\n",
        "  # jax.config.update('jax_enable_x64', True)\n",
        "\n",
        "ivy.set_backend(my_backend)\n",
        "\n",
        "# as of the pytorch mnist example https://github.com/pytorch/examples/blob/main/mnist/main.py\n",
        "class Net(ivy.Module):\n",
        "    def __init__(self):\n",
        "        self.conv1 = ivy.Conv2D(1, 32, [3, 3], 1, \"VALID\")\n",
        "        self.conv2 = ivy.Conv2D(32, 64, [3, 3], 1, \"VALID\")\n",
        "        self.conv1_drop = ivy.Dropout(0.25)\n",
        "        self.conv2_drop = ivy.Dropout(0.5)\n",
        "        self.fc1 = ivy.Linear(9216, 128)\n",
        "        self.fc2 = ivy.Linear(128, 10)\n",
        "        super().__init__()\n",
        "\n",
        "    def _forward(self, x):\n",
        "        x = self.conv1(x)\n",
        "        ivy.relu(x, out=x)\n",
        "        x = self.conv2(x)\n",
        "        ivy.relu(x, out=x)\n",
        "        x = ivy.max_pool2d(x, 2, 2, 'VALID')\n",
        "        x = self.conv1_drop(x)\n",
        "        x = ivy.flatten(x, start_dim=1)\n",
        "        x = self.fc1(x)\n",
        "        ivy.relu(x, out=x)\n",
        "        x = self.conv2_drop(x)\n",
        "        x = self.fc2(x)\n",
        "        x = ivy.softmax(x)\n",
        "        return x\n",
        "\n",
        "\n",
        "def loss_fn(v, x, y):\n",
        "    entropy = ivy.sparse_cross_entropy(y, model(x))\n",
        "    entropy = entropy.mean()\n",
        "    return entropy\n",
        "\n",
        "\n",
        "if doCompile:\n",
        "  print(\"starting compilation\")\n",
        "  model = ivy.compile(Net(), to=my_backend, args=(ivy.random_normal(shape=(1,28,28,1)),))\n",
        "else:\n",
        "  model = Net()\n",
        "print(\"done\")\n",
        "\n",
        "print('loading mnist')\n",
        "from keras.datasets import mnist\n",
        "(train_X_np, train_y_np), (test_X, test_y) = mnist.load_data()\n",
        "del test_X # I'm not there yet, lol\n",
        "del test_y\n",
        "\n",
        "# no need to look at all 60,000 samples as of now\n",
        "limit = 640\n",
        "train_X_np = train_X_np[:limit, :, :]\n",
        "train_y_np = train_y_np[:limit]\n",
        "\n",
        "# batch parameters\n",
        "batch_size = 32\n",
        "num_batches = limit // batch_size\n",
        "\n",
        "print('starting to batch')\n",
        "## convert to ivy\n",
        "train_X_ivy = ivy.array(train_X_np)\n",
        "train_y_ivy = ivy.array(train_y_np)\n",
        "\n",
        "# normalize from grey scale to 0.0-1.0\n",
        "train_X_ivy = train_X_ivy / 255\n",
        "\n",
        "# expand data from nhw to nhwc\n",
        "train_X_ivy = ivy.expand_dims(train_X_ivy, axis=-1)\n",
        "\n",
        "# turn big array into list of batched arrays\n",
        "train_X_batches = [train_X_ivy[i*batch_size:(i+1)*batch_size] for i in range(num_batches)]\n",
        "train_y_batches = [train_y_ivy[i*batch_size:(i+1)*batch_size] for i in range(num_batches)]\n",
        "print('done')\n",
        "\n",
        "for idx in range(num_batches):\n",
        "    loss, grads = ivy.execute_with_gradients(lambda v: loss_fn(v, train_X_batches[idx], train_y_batches[idx]), model.v)\n",
        "    print(f'{idx=}, {loss=}')\n",
        "    # print(f\"{grads=}\")\n",
        "    if grads.all().cont_all_false():\n",
        "        print(\"ERROR! Gradient is zero.\")\n",
        "        # print(f'{grads.conv1.w=}')\n",
        "        # print(f'{grads.conv1.b=}')\n",
        "        # print(f'{grads.conv2.w=}')\n",
        "        # print(f'{grads.conv2.b=}')\n",
        "        # print(f'{grads.fc1.w=}')\n",
        "        # print(f'{grads.fc1.b=}')\n",
        "        # print(f'{grads.fc2.w=}')\n",
        "        # print(f'{grads.fc2.b=}')\n",
        "        # break\n",
        "    model.v = model.v - grads * 0.005"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MkcTfkXhxt3R",
        "outputId": "51ce1d3b-2366-44d0-94c2-c9128c986859"
      },
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "starting compilation\n",
            "done\n",
            "loading mnist\n",
            "starting to batch\n",
            "done\n",
            "idx=0, loss=ivy.array(3.7165427)\n",
            "idx=1, loss=ivy.array(4.7488155)\n",
            "idx=2, loss=ivy.array(2.9973073)\n",
            "idx=3, loss=ivy.array(3.7921944)\n",
            "idx=4, loss=ivy.array(2.8538308)\n",
            "idx=5, loss=ivy.array(2.8732054)\n",
            "idx=6, loss=ivy.array(1.867829)\n",
            "idx=7, loss=ivy.array(2.162081)\n",
            "idx=8, loss=ivy.array(1.8395674)\n",
            "idx=9, loss=ivy.array(1.3294086)\n",
            "idx=10, loss=ivy.array(1.3219159)\n",
            "idx=11, loss=ivy.array(1.289132)\n",
            "idx=12, loss=ivy.array(1.5365679)\n",
            "idx=13, loss=ivy.array(1.3539488)\n",
            "idx=14, loss=ivy.array(1.7172174)\n",
            "idx=15, loss=ivy.array(2.002759)\n",
            "idx=16, loss=ivy.array(1.3632437)\n",
            "idx=17, loss=ivy.array(1.4038608)\n",
            "idx=18, loss=ivy.array(1.7802825)\n",
            "idx=19, loss=ivy.array(2.0346537)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "random_index = 3\n",
        "\n",
        "x = train_X_ivy[random_index]\n",
        "# expand hwc to nhwc\n",
        "x = ivy.expand_dims(x, axis=0)\n",
        "prediction = model(x)\n",
        "print(f'{prediction=}')\n",
        "print(f'{ivy.argmax(prediction)=}')\n",
        "print(f'{train_y_ivy[random_index]=}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bL23x8HB3zvh",
        "outputId": "36fed16d-b1c2-4bb9-d436-804fdbe4ead0"
      },
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "prediction=tensor([[4.1861e-04, 9.3942e-01, 5.4173e-03, 7.2766e-04, 7.3186e-04, 2.4030e-02,\n",
            "         7.7718e-05, 1.2671e-03, 2.5814e-02, 2.0968e-03]],\n",
            "       grad_fn=<SoftmaxBackward0>)\n",
            "ivy.argmax(prediction)=ivy.array(1)\n",
            "train_y_ivy[random_index]=ivy.array(1)\n"
          ]
        }
      ]
    }
  ]
}